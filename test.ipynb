{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain langchain_community langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL IMPORTS\n",
    "import os\n",
    "import re\n",
    "from langchain.schema import Document\n",
    "from rich import print\n",
    "from tqdm import tqdm\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RICH'S PRINT COLORS\n",
    "YELLOW = \"#fde047\"\n",
    "ORANGE = \"#f97316\"\n",
    "RED = \"#ef4444\"\n",
    "BLUE = \"#3b82f6\"\n",
    "CYAN = \"#06b6d4\"\n",
    "EMERALD = \"#34d399\"\n",
    "VIOLET = \"#a855f7\"\n",
    "PINK = \"#ec4899\"\n",
    "GRAY = \"#64748b\"\n",
    "WHITE = \"#cccccc\"\n",
    "GREEN = \"#3fb618\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL VARIABLES\n",
    "ROOT_DIR = \"../../../COLEGA DATA\"\n",
    "PDF_DIR = os.path.join(ROOT_DIR, \"notificaciones\")\n",
    "# Ruta al archivo PDF\n",
    "PDF_FILE_1 = os.path.join(PDF_DIR, \"RES 04-04-2024 - DILIGENCIA PRELIMINAR.pdf\")\n",
    "PDF_FILE_2 = os.path.join(\n",
    "    ROOT_DIR, \"MÉTODO DE LA DEMANDA Y SU CONTESTACIÓN/1_EL_CASO_Y_SU_SOLUCIÓN.pdf\"\n",
    ")\n",
    "\n",
    "print(f\"[{WHITE}]{PDF_DIR}\\n\\n{PDF_FILE_1}\\n\\n{PDF_FILE_2}[/]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans text by replacing non-breaking spaces, normalizing spaces and newlines,\n",
    "    and removing hash symbols.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Replace non-breaking spaces with regular spaces\n",
    "        text = text.replace(\"\\xa0\", \" \")\n",
    "        # Normalize spaces\n",
    "        text = re.sub(r\"\\s+\", \" \", text)\n",
    "        # Normalize newlines if specified\n",
    "        text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "        # Remove hash symbols if specified\n",
    "        text = re.sub(r\"#\", \"\", text)\n",
    "        # Trim leading and trailing whitespace\n",
    "        text = text.strip()\n",
    "\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while cleaning the text: {e}\")\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYMUPDF4LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pymupdf4llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymupdf4llm import to_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pymupdf4llm_directory_loader(directory_path: str) -> List[Document]:\n",
    "    \"\"\"LOADS PDF DOCUMENTS FROM A GIVEN DIRECTORY WITH PROGRESS INDICATOR.\"\"\"\n",
    "\n",
    "    if not os.path.exists(directory_path):\n",
    "        raise ValueError(\n",
    "            f\"pymupdf4llm_directory_loader() >>> DIRECTORY {directory_path} DOESN'T EXIST.\"\n",
    "        )\n",
    "\n",
    "    loaded_docs: List[Document] = []\n",
    "\n",
    "    # SEARCH IN THE GIVEN DIRECTORY FOR EACH PDF FILE IN IT AND GETS ITS PATH\n",
    "    pdf_files_info = []\n",
    "    for parent_dir_path, _, files in os.walk(directory_path):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".pdf\"):\n",
    "                file_path = os.path.join(parent_dir_path, filename)\n",
    "                pdf_files_info.append({\"file_name\": filename, \"file_path\": file_path})\n",
    "\n",
    "    # LOADS EACH PDF FILE: FILE --> LIST[DOCUMENT]\n",
    "    for file_info in tqdm(\n",
    "        pdf_files_info,\n",
    "        desc=\"LOADING PDF FILES\",\n",
    "        total=len(pdf_files_info),\n",
    "        colour=EMERALD,\n",
    "    ):\n",
    "        md_text = to_markdown(file_info[\"file_path\"], show_progress=False)\n",
    "        loaded_file = Document(metadata=file_info, page_content=md_text)\n",
    "\n",
    "        loaded_docs.append(loaded_file)\n",
    "\n",
    "    return loaded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pymupdf4llm_docs = pymupdf4llm_directory_loader(PDF_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pymupdf4llm_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, doc in enumerate(pymupdf4llm_docs):\n",
    "    print(\n",
    "        f\"[bold {BLUE}]> DOC N°:[/] [bold {WHITE}]{index}[/]\\n\",\n",
    "        f\"[bold {EMERALD}]> FILENAME:[/] [bold {WHITE}]{doc.metadata[\"file_name\"]}[/]\\n\\n\",\n",
    "        f\"[bold {YELLOW}]> CONTENT:[/]\\n[{WHITE}]{doc.page_content}[/]\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYTESSARACT / PDF2IMAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pytesseract pdf2image poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytesseract_directory_loader(directory_path: str) -> List[Document]:\n",
    "    \"\"\"LOADS PDF DOCUMENTS FROM A GIVEN DIRECTORY WITH PROGRESS INDICATOR.\"\"\"\n",
    "\n",
    "    if not os.path.exists(directory_path):\n",
    "        raise ValueError(\n",
    "            f\"pymupdf4llm_directory_loader() >>> DIRECTORY {directory_path} DOESN'T EXIST.\"\n",
    "        )\n",
    "\n",
    "    loaded_docs: List[Document] = []\n",
    "\n",
    "    # SEARCH IN THE GIVEN DIRECTORY FOR EACH PDF FILE IN IT AND GETS ITS PATH\n",
    "    pdf_files_info = []\n",
    "    for parent_dir_path, _, files in os.walk(directory_path):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".pdf\"):\n",
    "                file_path = os.path.join(parent_dir_path, filename)\n",
    "                pdf_files_info.append({\"file_name\": filename, \"file_path\": file_path})\n",
    "\n",
    "    # CONVERTS EACH PDF FILE INTO A LIST[PNG]\n",
    "    for file_info in tqdm(\n",
    "        pdf_files_info,\n",
    "        desc=\"LOADING PDF FILES\",\n",
    "        total=len(pdf_files_info),\n",
    "        colour=EMERALD,\n",
    "    ):\n",
    "        pages_imgs = convert_from_path(file_info[\"file_path\"])\n",
    "        pages = []\n",
    "        for page in pages_imgs:\n",
    "            page_extracted_text = pytesseract.image_to_string(page, lang=\"spa\")\n",
    "            pages.append(page_extracted_text)\n",
    "\n",
    "        content = \"\\n\".join(page for page in pages)\n",
    "\n",
    "        loaded_file = Document(metadata=file_info, page_content=content)\n",
    "        loaded_docs.append(loaded_file)\n",
    "\n",
    "    return loaded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract_docs = pytesseract_directory_loader(PDF_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pytesseract_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, doc in enumerate(pytesseract_docs):\n",
    "    print(\n",
    "        f\"[bold {BLUE}]> DOC N°:[/] [bold {WHITE}]{index}[/]\\n\",\n",
    "        f\"[bold {EMERALD}]> FILENAME:[/] [bold {WHITE}]{doc.metadata[\"file_name\"]}[/]\\n\\n\",\n",
    "        f\"[bold {YELLOW}]> CONTENT:[/]\\n[{WHITE}]{doc.page_content}[/]\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MARKER-PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: #f97316; font-weight: bold\">!TODO: </span>CHECK OUT WHATS GOING ON HERE\n",
    "\n",
    "<span style=\"color: #64748b\">RuntimeError: MPS backend out of memory (MPS allocated: 9.06 GB, other allocations: 3.52 MB, max allowed: 9.07 GB). Tried to allocate 2.50 KB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU marker-pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from marker.converters.pdf import PdfConverter\n",
    "from marker.models import create_model_dict\n",
    "from marker.output import text_from_rendered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "def marker_directory_loader(directory_path: str) -> List[Document]:\n",
    "    \"\"\"LOADS PDF DOCUMENTS FROM A GIVEN DIRECTORY WITH PROGRESS INDICATOR.\"\"\"\n",
    "\n",
    "    if not os.path.exists(directory_path):\n",
    "        raise ValueError(\n",
    "            f\"marker_directory_loader() >>> DIRECTORY {directory_path} DOESN'T EXIST.\"\n",
    "        )\n",
    "\n",
    "    loaded_docs: List[Document] = []\n",
    "\n",
    "    # SEARCH IN THE GIVEN DIRECTORY FOR EACH PDF FILE IN IT AND GETS ITS PATH\n",
    "    pdf_files_info = []\n",
    "    for parent_dir_path, _, files in os.walk(directory_path):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".pdf\"):\n",
    "                file_path = os.path.join(parent_dir_path, filename)\n",
    "                pdf_files_info.append({\"file_name\": filename, \"file_path\": file_path})\n",
    "\n",
    "    # LOADS EACH PDF FILE: FILE --> LIST[DOCUMENT]\n",
    "    for file_info in tqdm(\n",
    "        pdf_files_info,\n",
    "        desc=\"LOADING PDF FILES\",\n",
    "        total=len(pdf_files_info),\n",
    "        colour=EMERALD,\n",
    "    ):\n",
    "        converter = PdfConverter(\n",
    "            artifact_dict=create_model_dict(),\n",
    "        )\n",
    "\n",
    "        rendered = converter(file_info[\"file_path\"])\n",
    "        text, _, images = text_from_rendered(rendered)\n",
    "        loaded_file = Document(metadata=file_info, page_content=text)\n",
    "\n",
    "        loaded_docs.append(loaded_file)\n",
    "\n",
    "    return loaded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "marker_docs = marker_directory_loader(PDF_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SURYA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pdf2image surya-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "from surya.recognition import RecognitionPredictor\n",
    "from surya.detection import DetectionPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNFINISHED\n",
    "def pytesseract_directory_loader(directory_path: str) -> List[Document]:\n",
    "    \"\"\"LOADS PDF DOCUMENTS FROM A GIVEN DIRECTORY WITH PROGRESS INDICATOR.\"\"\"\n",
    "\n",
    "    if not os.path.exists(directory_path):\n",
    "        raise ValueError(\n",
    "            f\"pymupdf4llm_directory_loader() >>> DIRECTORY {directory_path} DOESN'T EXIST.\"\n",
    "        )\n",
    "\n",
    "    loaded_docs: List[Document] = []\n",
    "\n",
    "    # SEARCH IN THE GIVEN DIRECTORY FOR EACH PDF FILE IN IT AND GETS ITS PATH\n",
    "    pdf_files_info = []\n",
    "    for parent_dir_path, _, files in os.walk(directory_path):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".pdf\"):\n",
    "                file_path = os.path.join(parent_dir_path, filename)\n",
    "                pdf_files_info.append({\"file_name\": filename, \"file_path\": file_path})\n",
    "\n",
    "    langs = [\"es\", \"en\"]\n",
    "\n",
    "    recognition_predictor = RecognitionPredictor()\n",
    "    detection_predictor = DetectionPredictor()\n",
    "    # CONVERTS EACH PDF FILE INTO A LIST[PNG]\n",
    "    for file_info in tqdm(\n",
    "        pdf_files_info,\n",
    "        desc=\"LOADING PDF FILES\",\n",
    "        total=len(pdf_files_info),\n",
    "        colour=EMERALD,\n",
    "    ):\n",
    "        pages_imgs = convert_from_path(file_info[\"file_path\"])\n",
    "        pages = []\n",
    "        for page in pages_imgs:\n",
    "            page_extracted_text = pytesseract.image_to_string(page, lang=\"spa\")\n",
    "            pages.append(page_extracted_text)\n",
    "\n",
    "        content = \"\\n\".join(page for page in pages)\n",
    "\n",
    "        loaded_file = Document(metadata=file_info, page_content=content)\n",
    "        loaded_docs.append(loaded_file)\n",
    "\n",
    "    return loaded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = convert_from_path(PDF_FILE_1)\n",
    "\n",
    "langs = [\"es\", \"en\"]\n",
    "\n",
    "recognition_predictor = RecognitionPredictor()\n",
    "detection_predictor = DetectionPredictor()\n",
    "\n",
    "predictions_per_page = [\n",
    "    recognition_predictor([page], [langs], detection_predictor) for page in pages\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each page\n",
    "txt = \"\"\n",
    "for prediction in predictions_per_page:\n",
    "    for ocr_result in prediction:\n",
    "        for text_line in ocr_result.text_lines:\n",
    "            txt += f\"\\n{text_line.text}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TROCOCR\n",
    "<span style=\"color: #fde047; font-weight: bold; font-size: x-large\">UNTESTED</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "import requests\n",
    "from PIL import Image\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-handwritten\")\n",
    "\n",
    "# load image from the IAM dataset\n",
    "url = \"https://fki.tic.heia-fr.ch/static/img/a01-122-02.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
    "\n",
    "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "generated_ids = model.generate(pixel_values)\n",
    "\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOCTR\n",
    "<span style=\"color: #fde047; font-weight: bold; font-size: x-large\">UNTESTED</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU python-doctr \"python-doctr[tf]\" \"python-doctr[torch]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from doctr.io import DocumentFile\n",
    "from doctr.models import ocr_predictor\n",
    "\n",
    "model = ocr_predictor(\n",
    "    det_arch=\"db_resnet50\", reco_arch=\"crnn_vgg16_bn\", pretrained=True\n",
    ")\n",
    "\n",
    "# read file\n",
    "img = DocumentFile.from_images(img_path1)\n",
    "\n",
    "# use pre-trained model\n",
    "result = model(img)\n",
    "\n",
    "# export the result as a nested dict\n",
    "extract_info = result.export()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PYOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyocr\n",
    "import pyocr.builders\n",
    "\n",
    "# Ruta al archivo PDF\n",
    "pdf_path = (\n",
    "    \"../../../COLEGA DATA/notificaciones/RES 04-04-2024 - DILIGENCIA PRELIMINAR.pdf\"\n",
    ")\n",
    "# pdf_path = \"../../../COLEGA DATA/MÉTODO DE LA DEMANDA Y SU CONTESTACIÓN/1_EL_CASO_Y_SU_SOLUCIÓN.pdf\"\n",
    "\n",
    "pages = convert_from_path(pdf_path)\n",
    "\n",
    "tools = pyocr.get_available_tools()\n",
    "tool = ValueError(\"No tools found\") if len(tools) == 0 else tools[0]\n",
    "langs = tool.get_available_languages()\n",
    "lang = ValueError(\"'spa' is not available\") if \"spa\" not in langs else \"spa\"\n",
    "\n",
    "loaded_pages = []\n",
    "for page in pages:\n",
    "    txt: str = tool.image_to_string(\n",
    "        page, lang=\"spa\", builder=pyocr.builders.TextBuilder()\n",
    "    )\n",
    "    loaded_pages.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\".join(loaded_pages))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
