{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERALS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain langchain_community langchain_core pdf2image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL IMPORTS\n",
    "import re\n",
    "import numpy as np\n",
    "from langchain.schema import Document\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "from rich import print\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RICH'S PRINT COLORS\n",
    "YELLOW = \"#fde047\"\n",
    "ORANGE = \"#f97316\"\n",
    "RED = \"#ef4444\"\n",
    "BLUE = \"#3b82f6\"\n",
    "CYAN = \"#06b6d4\"\n",
    "EMERALD = \"#34d399\"\n",
    "VIOLET = \"#a855f7\"\n",
    "PINK = \"#ec4899\"\n",
    "GRAY = \"#64748b\"\n",
    "WHITE = \"#cccccc\"\n",
    "GREEN = \"#3fb618\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL VARIABLES\n",
    "ROOT_DIR = Path(\"../../../COLEGA DATA\")\n",
    "PDF_DIR = ROOT_DIR / \"notificaciones\"\n",
    "PDF_FILE_1 = PDF_DIR / \"RES 04-04-2024 - DILIGENCIA PRELIMINAR.pdf\"\n",
    "PDF_FILE_2 = (\n",
    "    ROOT_DIR / \"MÉTODO DE LA DEMANDA Y SU CONTESTACIÓN/1_EL_CASO_Y_SU_SOLUCIÓN.pdf\"\n",
    ")\n",
    "\n",
    "\n",
    "# print(f\"[{WHITE}]{PDF_DIR}\\n\\n{PDF_FILE_1}\\n\\n{PDF_FILE_2}[/]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_dir(dir_path: str, file_ext: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"FILE'S SEARCH IN A GIVEN DIRECTORY\"\"\"\n",
    "    dir_path = Path(dir_path)\n",
    "\n",
    "    if not dir_path.is_dir():\n",
    "        raise ValueError(f\"search_dir() => DIRECTORY ({dir_path}) DOESN'T EXIST.\")\n",
    "\n",
    "    if not any(dir_path.iterdir()):\n",
    "        raise ValueError(f\"search_dir() => DIRECTORY ({dir_path}) IS EMPTY.\")\n",
    "\n",
    "    if not file_ext.startswith(\".\"):\n",
    "        file_ext = f\".{file_ext}\"\n",
    "\n",
    "    # SEARCH FOR WANTED FILES\n",
    "    files_info: List[Dict[str, str]] = [\n",
    "        {\"filename\": f.name, \"filepath\": str(f)}\n",
    "        for f in dir_path.glob(f\"*{file_ext}\")\n",
    "        if f.is_file()\n",
    "    ]\n",
    "\n",
    "    # CHECK IF FILES WERE FOUND\n",
    "    if not files_info:\n",
    "        raise ValueError(\n",
    "            f\"search_dir() => NO FILES WITH EXTENSION ({file_ext}) WERE FOUND IN DIRECTORY ({dir_path}).\"\n",
    "        )\n",
    "\n",
    "    return files_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans text by replacing non-breaking spaces, normalizing spaces and newlines,\n",
    "    and removing hash symbols.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Replace non-breaking spaces with regular spaces\n",
    "        text = text.replace(\"\\xa0\", \" \")\n",
    "        # Normalize spaces\n",
    "        text = re.sub(r\"\\s+\", \" \", text)\n",
    "        # Normalize newlines if specified\n",
    "        text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "        # Remove hash symbols if specified\n",
    "        text = re.sub(r\"#\", \"\", text)\n",
    "        # Trim leading and trailing whitespace\n",
    "        text = text.strip()\n",
    "\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while cleaning the text: {e}\")\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyMuPDF4llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pymupdf4llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymupdf4llm import to_markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf4llm_directory_loader(dir_path: str, file_ext: str) -> List[Document]:\n",
    "    \"\"\"LOADS PDF DOCUMENTS FROM A GIVEN DIRECTORY\"\"\"\n",
    "\n",
    "    # SEARCH IN THE GIVEN DIRECTORY FOR EACH PDF FILE IN IT AND GETS ITS PATH\n",
    "    loaded_docs: List[Document] = []\n",
    "    files_info: List[Dict[str, str]] = search_dir(dir_path, file_ext)\n",
    "\n",
    "    # LOADS EACH PDF FILE: FILE --> LIST[DOCUMENT]\n",
    "    for f in tqdm(\n",
    "        files_info, desc=\"LOADING PDF FILES\", total=len(files_info), colour=EMERALD\n",
    "    ):\n",
    "        md_text = to_markdown(f[\"filepath\"], show_progress=False)\n",
    "        loaded_file = Document(metadata=f, page_content=md_text)\n",
    "\n",
    "        loaded_docs.append(loaded_file)\n",
    "\n",
    "    return loaded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf4llm_docs = pdf4llm_directory_loader(PDF_DIR, \"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, doc in enumerate(pdf4llm_docs):\n",
    "    print(\n",
    "        f\"[bold {BLUE}]> DOC N°:[/] [bold {WHITE}]{index}[/]\\n\",\n",
    "        f\"[bold {EMERALD}]> FILENAME:[/] [bold {WHITE}]{doc.metadata[\"filename\"]}[/]\\n\\n\",\n",
    "        f\"[bold {YELLOW}]> CONTENT:[/]\\n[{WHITE}]{doc.page_content}[/]\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTesseract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytesseract import image_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytess_directory_loader(dir_path: str, file_ext: str) -> List[Document]:\n",
    "    \"\"\"LOADS PDF DOCUMENTS FROM A GIVEN DIRECTORY\"\"\"\n",
    "\n",
    "    # SEARCH IN THE GIVEN DIRECTORY FOR EACH PDF FILE IN IT AND GETS ITS PATH\n",
    "    loaded_docs: List[Document] = []\n",
    "    files_info: List[Dict[str, str]] = search_dir(dir_path, file_ext)\n",
    "\n",
    "    for f in tqdm(\n",
    "        files_info,\n",
    "        desc=\"LOADING PDF FILES\",\n",
    "        total=len(files_info),\n",
    "        colour=EMERALD,\n",
    "    ):\n",
    "        f_pages_imgs = convert_from_path(f[\"filepath\"])\n",
    "\n",
    "        pages = []\n",
    "        for page in f_pages_imgs:\n",
    "            page_extracted_text = image_to_string(page, lang=\"spa\")\n",
    "            pages.append(page_extracted_text)\n",
    "\n",
    "        content = \"\\n\".join(page for page in pages)\n",
    "\n",
    "        loaded_file = Document(metadata=f, page_content=content)\n",
    "        loaded_docs.append(loaded_file)\n",
    "\n",
    "    return loaded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytess_docs = pytess_directory_loader(PDF_DIR, \"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, doc in enumerate(pytess_docs):\n",
    "    print(\n",
    "        f\"[bold {BLUE}]> DOC N°:[/] [bold {WHITE}]{index}[/]\\n\",\n",
    "        f\"[bold {EMERALD}]> FILENAME:[/] [bold {WHITE}]{doc.metadata[\"filename\"]}[/]\\n\\n\",\n",
    "        f\"[bold {YELLOW}]> CONTENT:[/]\\n[{WHITE}]{doc.page_content}[/]\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SuryaOCR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU surya-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surya.recognition import RecognitionPredictor\n",
    "from surya.detection import DetectionPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = convert_from_path(PDF_FILE_1)\n",
    "\n",
    "langs = [\"es\", \"en\"]\n",
    "\n",
    "recognition_predictor = RecognitionPredictor()\n",
    "detection_predictor = DetectionPredictor()\n",
    "\n",
    "predictions_per_page = [\n",
    "    recognition_predictor([page], [langs], detection_predictor) for page in pages\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each page\n",
    "txt = \"\"\n",
    "for prediction in predictions_per_page:\n",
    "    for ocr_result in prediction:\n",
    "        for text_line in ocr_result.text_lines:\n",
    "            txt += f\"\\n{text_line.text}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyOCR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyocr\n",
    "import pyocr.builders\n",
    "\n",
    "# Ruta al archivo PDF\n",
    "pdf_path = (\n",
    "    \"../../../COLEGA DATA/notificaciones/RES 04-04-2024 - DILIGENCIA PRELIMINAR.pdf\"\n",
    ")\n",
    "# pdf_path = \"../../../COLEGA DATA/MÉTODO DE LA DEMANDA Y SU CONTESTACIÓN/1_EL_CASO_Y_SU_SOLUCIÓN.pdf\"\n",
    "\n",
    "pages = convert_from_path(pdf_path)\n",
    "\n",
    "tools = pyocr.get_available_tools()\n",
    "tool = ValueError(\"No tools found\") if len(tools) == 0 else tools[0]\n",
    "langs = tool.get_available_languages()\n",
    "lang = ValueError(\"'spa' is not available\") if \"spa\" not in langs else \"spa\"\n",
    "\n",
    "loaded_pages = []\n",
    "for page in pages:\n",
    "    txt: str = tool.image_to_string(\n",
    "        page, lang=\"spa\", builder=pyocr.builders.TextBuilder()\n",
    "    )\n",
    "    loaded_pages.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\".join(loaded_pages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EasyOCR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Valores comunes de DPI:\n",
    "\n",
    "- 72-96: Calidad web/pantalla\n",
    "- 150: Calidad media\n",
    "- 300: Alta calidad, buen balance entre resolución y tamaño de archivo\n",
    "- 600: Muy alta calidad, archivos más pesados\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easyocr_directory_loader(directory_path: str) -> List[Document]:\n",
    "    \"\"\"LOADS PDF DOCUMENTS FROM A GIVEN DIRECTORY WITH PROGRESS INDICATOR.\"\"\"\n",
    "\n",
    "    if not os.path.exists(directory_path):\n",
    "        raise ValueError(\n",
    "            f\"pymupdf4llm_directory_loader() >>> DIRECTORY {directory_path} DOESN'T EXIST.\"\n",
    "        )\n",
    "\n",
    "    loaded_docs: List[Document] = []\n",
    "\n",
    "    # SEARCH IN THE GIVEN DIRECTORY FOR EACH PDF FILE IN IT AND GETS ITS PATH\n",
    "    pdf_files_info = []\n",
    "    for parent_dir_path, _, files in os.walk(directory_path):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".pdf\"):\n",
    "                file_path = os.path.join(parent_dir_path, filename)\n",
    "                pdf_files_info.append({\"file_name\": filename, \"file_path\": file_path})\n",
    "\n",
    "    # CONVERTS EACH PDF FILE INTO A LIST[PNG]\n",
    "    for file_info in tqdm(\n",
    "        pdf_files_info,\n",
    "        desc=\"LOADING PDF FILES\",\n",
    "        total=len(pdf_files_info),\n",
    "        colour=EMERALD,\n",
    "    ):\n",
    "        # Initialize EasyOCR reader for Spanish and English\n",
    "        reader = easyocr.Reader([\"es\", \"en\"])\n",
    "        pages_imgs = convert_from_path(file_info[\"file_path\"])\n",
    "        loaded_pages = []\n",
    "        for page in pages_imgs:\n",
    "            # EasyOCR reads the text\n",
    "            results = reader.readtext(np.array(page))\n",
    "            # Extract text from results\n",
    "            page_text = \" \".join([text[1] for text in results])\n",
    "\n",
    "            loaded_pages.append(page_text)\n",
    "\n",
    "        content = \"\\n\".join(page for page in loaded_pages)\n",
    "\n",
    "        loaded_file = Document(metadata=file_info, page_content=content)\n",
    "        loaded_docs.append(loaded_file)\n",
    "\n",
    "    return loaded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easyocr_docs = easyocr_directory_loader(PDF_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
