{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERALS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain_community langchain_core pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL IMPORTS\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from langchain_core.documents import Document\n",
    "from pathlib import Path\n",
    "from pdf2image import convert_from_path\n",
    "from rich import print\n",
    "from tqdm import tqdm\n",
    "from typing import List, Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RICH'S PRINT COLORS\n",
    "YELLOW = \"#fde047\"\n",
    "ORANGE = \"#f97316\"\n",
    "RED = \"#ef4444\"\n",
    "BLUE = \"#3b82f6\"\n",
    "CYAN = \"#06b6d4\"\n",
    "EMERALD = \"#34d399\"\n",
    "VIOLET = \"#a855f7\"\n",
    "PINK = \"#ec4899\"\n",
    "GRAY = \"#64748b\"\n",
    "WHITE = \"#cccccc\"\n",
    "GREEN = \"#3fb618\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL VARIABLES\n",
    "ROOT_DIR = Path(\"../../../../COLEGA DATA\")\n",
    "PDF_DIR = ROOT_DIR / \"notificaciones\"\n",
    "PDF_DIR_2 = ROOT_DIR / \"MÉTODO DE LA DEMANDA Y SU CONTESTACIÓN\" / \"CAPS\"\n",
    "PDF_FILE_1 = PDF_DIR / \"RES 04-04-2024 - DILIGENCIA PRELIMINAR.pdf\"\n",
    "PDF_FILE_2 = PDF_DIR_2 / \"1_EL_CASO_Y_SU_SOLUCIÓN.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_dir(dir_path: str, file_ext: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"FILE'S SEARCH IN A GIVEN DIRECTORY\"\"\"\n",
    "    dir_path = Path(dir_path)\n",
    "\n",
    "    if not dir_path.is_dir():\n",
    "        raise ValueError(f\"search_dir() => DIRECTORY ({dir_path}) DOESN'T EXIST.\")\n",
    "\n",
    "    if not any(dir_path.iterdir()):\n",
    "        raise ValueError(f\"search_dir() => DIRECTORY ({dir_path}) IS EMPTY.\")\n",
    "\n",
    "    if not file_ext.startswith(\".\"):\n",
    "        file_ext = f\".{file_ext}\"\n",
    "\n",
    "    # SEARCH FOR WANTED FILES\n",
    "    files_info: List[Dict[str, str]] = [\n",
    "        {\"filename\": f.name, \"filepath\": str(f)}\n",
    "        for f in dir_path.glob(f\"*{file_ext}\")\n",
    "        if f.is_file()\n",
    "    ]\n",
    "\n",
    "    # CHECK IF FILES WERE FOUND\n",
    "    if not files_info:\n",
    "        raise ValueError(\n",
    "            f\"search_dir() => NO FILES WITH EXTENSION ({file_ext}) WERE FOUND IN DIRECTORY ({dir_path}).\"\n",
    "        )\n",
    "\n",
    "    return files_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaner(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Cleans text by replacing non-breaking spaces, normalizing spaces and newlines,\n",
    "    and removing hash symbols.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Replace non-breaking spaces with regular spaces\n",
    "        text = text.replace(\"\\xa0\", \" \")\n",
    "        # Normalize spaces\n",
    "        text = re.sub(r\"\\s+\", \" \", text)\n",
    "        # Normalize newlines if specified\n",
    "        text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text)\n",
    "        # Remove hash symbols if specified\n",
    "        text = re.sub(r\"#\", \"\", text)\n",
    "        # Trim leading and trailing whitespace\n",
    "        text = text.strip()\n",
    "\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while cleaning the text: {e}\")\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_text_corrupt(text) -> bool:\n",
    "    \"\"\"Verifica si el texto extraído contiene caracteres corruptos o codificado incorrectamente.\"\"\"\n",
    "    if not text.strip():\n",
    "        return True\n",
    "\n",
    "    # Contar caracteres alfabéticos, espacios y caracteres extraños\n",
    "    total_chars = len(text)\n",
    "    valid_chars = sum(c.isalpha() or c.isspace() for c in text)\n",
    "    invalid_chars = sum(1 for c in text if c in \"�\")  # Caracteres de reemplazo o BOM\n",
    "\n",
    "    # Si hay demasiados caracteres extraños o pocos alfabéticos, marcar como corrupto\n",
    "    if (valid_chars / total_chars) < 0.7:\n",
    "        # if (invalid_chars / total_chars) > 0.3:\n",
    "        return True\n",
    "\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf4llm_directory_loader(dir_path: str, file_ext: str) -> List[Document]:\n",
    "    \"\"\"LOADS PDF DOCUMENTS FROM A GIVEN DIRECTORY\"\"\"\n",
    "\n",
    "    # SEARCH IN THE GIVEN DIRECTORY FOR EACH PDF FILE IN IT AND GETS ITS PATH\n",
    "    loaded_docs: List[Document] = []\n",
    "    files_info: List[Dict[str, str]] = search_dir(dir_path, file_ext)\n",
    "\n",
    "    # LOADS EACH PDF FILE: FILE --> LIST[DOCUMENT]\n",
    "    for f in tqdm(\n",
    "        files_info, desc=\"LOADING PDF FILES\", total=len(files_info), colour=EMERALD\n",
    "    ):\n",
    "        md_text = to_markdown(f[\"filepath\"], show_progress=False)\n",
    "        loaded_file = Document(metadata=f, page_content=md_text)\n",
    "\n",
    "        loaded_docs.append(loaded_file)\n",
    "\n",
    "    return loaded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf4llm_docs = pdf4llm_directory_loader(PDF_DIR, \"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, doc in enumerate(pdf4llm_docs):\n",
    "    if is_text_corrupt(doc.page_content):\n",
    "        print(f\"[{RED}]{doc.metadata['filename']}[/]\")\n",
    "    else:\n",
    "        print(f\"[{GREEN}]{doc.metadata['filename']}[/]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs = pdf4llm_directory_loader(PDF_DIR_2, \"pdf\")\n",
    "\n",
    "for index, doc in enumerate(test_docs):\n",
    "    if is_text_corrupt(doc.page_content):\n",
    "        print(f\"[{RED}]{doc.metadata['filename']}[/]\")\n",
    "    else:\n",
    "        print(f\"[{GREEN}]{doc.metadata['filename']}[/]\")\n",
    "\n",
    "for index, doc in enumerate(test_docs):\n",
    "    print(\n",
    "        f\"[bold {BLUE}]> DOC N°:[/] [bold {WHITE}]{index}[/]\\n\",\n",
    "        f\"[bold {EMERALD}]> FILENAME:[/] [bold {WHITE}]{doc.metadata[\"filename\"]}[/]\\n\\n\",\n",
    "        f\"[bold {YELLOW}]> CONTENT:[/]\\n[{WHITE}]{doc.page_content[:500]}[/]\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTesseract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytesseract import image_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytess_directory_loader(dir_path: str, file_ext: str) -> List[Document]:\n",
    "    \"\"\"LOADS PDF DOCUMENTS FROM A GIVEN DIRECTORY\"\"\"\n",
    "\n",
    "    # SEARCH IN THE GIVEN DIRECTORY FOR EACH PDF FILE IN IT AND GETS ITS PATH\n",
    "    loaded_docs: List[Document] = []\n",
    "    files_info: List[Dict[str, str]] = search_dir(dir_path, file_ext)\n",
    "\n",
    "    for f in tqdm(\n",
    "        files_info,\n",
    "        desc=\"LOADING PDF FILES\",\n",
    "        total=len(files_info),\n",
    "        colour=EMERALD,\n",
    "    ):\n",
    "        f_pages_imgs = convert_from_path(f[\"filepath\"])\n",
    "\n",
    "        pages = []\n",
    "        for page in f_pages_imgs:\n",
    "            page_extracted_text = image_to_string(page, lang=\"spa\")\n",
    "            pages.append(page_extracted_text)\n",
    "\n",
    "        content = \"\\n\".join(page for page in pages)\n",
    "\n",
    "        loaded_file = Document(metadata=f, page_content=content)\n",
    "        loaded_docs.append(loaded_file)\n",
    "\n",
    "    return loaded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytess_docs = pytess_directory_loader(PDF_DIR, \"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, doc in enumerate(pytess_docs):\n",
    "    print(\n",
    "        f\"[bold {BLUE}]> DOC N°:[/] [bold {WHITE}]{index}[/]\\n\",\n",
    "        f\"[bold {EMERALD}]> FILENAME:[/] [bold {WHITE}]{doc.metadata[\"filename\"]}[/]\\n\\n\",\n",
    "        f\"[bold {YELLOW}]> CONTENT:[/]\\n[{WHITE}]{doc.page_content}[/]\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SuryaOCR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU surya-ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surya.recognition import RecognitionPredictor\n",
    "from surya.detection import DetectionPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = convert_from_path(PDF_FILE_1)\n",
    "\n",
    "langs = [\"es\", \"en\"]\n",
    "\n",
    "recognition_predictor = RecognitionPredictor()\n",
    "detection_predictor = DetectionPredictor()\n",
    "\n",
    "predictions_per_page = [\n",
    "    recognition_predictor([page], [langs], detection_predictor) for page in pages\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through each page\n",
    "txt = \"\"\n",
    "for prediction in predictions_per_page:\n",
    "    for ocr_result in prediction:\n",
    "        for text_line in ocr_result.text_lines:\n",
    "            txt += f\"\\n{text_line.text}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyOCR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU pyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyocr\n",
    "import pyocr.builders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pyocr_directory_loader(dir_path: str, file_ext: str) -> List[Document]:\n",
    "    \"\"\"LOADS PDF DOCUMENTS FROM A GIVEN DIRECTORY\"\"\"\n",
    "\n",
    "    loaded_docs: List[Document] = []\n",
    "    files_info: List[Dict[str, str]] = search_dir(dir_path, file_ext)\n",
    "\n",
    "    tools = pyocr.get_available_tools()\n",
    "    tool = (\n",
    "        ValueError(\"pyocr_directory_loader() => NO TOOLS FOUND\")\n",
    "        if len(tools) == 0\n",
    "        else tools[0]\n",
    "    )\n",
    "    langs = tool.get_available_languages()\n",
    "    lang = (\n",
    "        ValueError(\"pyocr_directory_loader() => 'spa' IS NOT AVAILABLE\")\n",
    "        if \"spa\" not in langs\n",
    "        else \"spa\"\n",
    "    )\n",
    "\n",
    "    for f in tqdm(\n",
    "        files_info,\n",
    "        desc=\"LOADING PDF FILES\",\n",
    "        total=len(files_info),\n",
    "        colour=EMERALD,\n",
    "    ):\n",
    "        f_pages_imgs = convert_from_path(f[\"filepath\"])\n",
    "\n",
    "        pages = []\n",
    "        for page in f_pages_imgs:\n",
    "            page_extracted_text = tool.image_to_string(\n",
    "                page, lang=lang, builder=pyocr.builders.TextBuilder()\n",
    "            )\n",
    "            pages.append(page_extracted_text)\n",
    "\n",
    "        content = \"\\n\".join(page for page in pages)\n",
    "\n",
    "        loaded_file = Document(metadata=f, page_content=content)\n",
    "        loaded_docs.append(loaded_file)\n",
    "\n",
    "    return loaded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyocr_docs = pyocr_directory_loader(PDF_DIR, \"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, doc in enumerate(pyocr_docs):\n",
    "    print(\n",
    "        f\"[bold {BLUE}]> DOC N°:[/] [bold {WHITE}]{index}[/]\\n\",\n",
    "        f\"[bold {EMERALD}]> FILENAME:[/] [bold {WHITE}]{doc.metadata[\"filename\"]}[/]\\n\\n\",\n",
    "        f\"[bold {YELLOW}]> CONTENT:[/]\\n[{WHITE}]{doc.page_content}[/]\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_docs = pyocr_directory_loader(PDF_DIR_2, \"pdf\")\n",
    "\n",
    "for index, doc in enumerate(test_docs):\n",
    "    if is_text_corrupt(doc.page_content):\n",
    "        print(f\"[{RED}]{doc.metadata['filename']}[/]\")\n",
    "    else:\n",
    "        print(f\"[{GREEN}]{doc.metadata['filename']}[/]\")\n",
    "\n",
    "for index, doc in enumerate(test_docs):\n",
    "    print(\n",
    "        f\"[bold {BLUE}]> DOC N°:[/] [bold {WHITE}]{index}[/]\\n\",\n",
    "        f\"[bold {EMERALD}]> FILENAME:[/] [bold {WHITE}]{doc.metadata[\"filename\"]}[/]\\n\\n\",\n",
    "        f\"[bold {YELLOW}]> CONTENT:[/]\\n[{WHITE}]{doc.page_content[:250]}[/]\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EasyOCR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def easyocr_directory_loader(dir_path: str, file_ext: str) -> List[Document]:\n",
    "    \"\"\"LOADS PDF DOCUMENTS FROM A GIVEN DIRECTORY WITH PROGRESS INDICATOR.\"\"\"\n",
    "\n",
    "    loaded_docs: List[Document] = []\n",
    "\n",
    "    files_info: List[Dict[str, str]] = search_dir(dir_path, file_ext)\n",
    "\n",
    "    # Initialize EasyOCR reader for Spanish and English\n",
    "    reader = easyocr.Reader([\"es\", \"en\"])\n",
    "\n",
    "    for f in tqdm(\n",
    "        files_info,\n",
    "        desc=\"LOADING PDF FILES\",\n",
    "        total=len(files_info),\n",
    "        colour=EMERALD,\n",
    "    ):\n",
    "        f_pages_imgs = convert_from_path(f[\"filepath\"])\n",
    "\n",
    "        loaded_pages = []\n",
    "        for page in f_pages_imgs:\n",
    "            # EasyOCR reads the text\n",
    "            results = reader.readtext(np.array(page))\n",
    "            # Extract text from results\n",
    "            page_text = \" \".join([text[1] for text in results])\n",
    "\n",
    "            loaded_pages.append(page_text)\n",
    "\n",
    "        content = \"\\n\".join(page for page in loaded_pages)\n",
    "\n",
    "        loaded_file = Document(metadata=f, page_content=content)\n",
    "        loaded_docs.append(loaded_file)\n",
    "\n",
    "    return loaded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "easyocr_docs = easyocr_directory_loader(PDF_DIR, \"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, doc in enumerate(easyocr_docs):\n",
    "    print(\n",
    "        f\"[bold {BLUE}]> DOC N°:[/] [bold {WHITE}]{index}[/]\\n\",\n",
    "        f\"[bold {EMERALD}]> FILENAME:[/] [bold {WHITE}]{doc.metadata[\"filename\"]}[/]\\n\\n\",\n",
    "        f\"[bold {YELLOW}]> CONTENT:[/]\\n[{WHITE}]{doc.page_content}[/]\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU docling langchain-docling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def docling_directory_loader(dir_path: str, file_ext: str) -> List[Document]:\n",
    "    \"\"\"LOADS PDF DOCUMENTS FROM A GIVEN DIRECTORY\"\"\"\n",
    "\n",
    "    # SEARCH IN THE GIVEN DIRECTORY FOR EACH PDF FILE IN IT AND GETS ITS PATH\n",
    "    loaded_docs: List[Document] = []\n",
    "    files_info: List[Dict[str, str]] = search_dir(dir_path, file_ext)\n",
    "\n",
    "    # LOADS EACH PDF FILE: FILE --> LIST[DOCUMENT]\n",
    "    for f in tqdm(\n",
    "        files_info, desc=\"LOADING PDF FILES\", total=len(files_info), colour=EMERALD\n",
    "    ):\n",
    "        converter = DocumentConverter()\n",
    "        result = converter.convert(f[\"filepath\"])\n",
    "        extracted_text = result.document.export_to_text()\n",
    "\n",
    "        loaded_file = Document(metadata=f, page_content=extracted_text)\n",
    "        loaded_docs.append(loaded_file)\n",
    "\n",
    "    return loaded_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docling_docs = docling_directory_loader(PDF_DIR, \"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, doc in enumerate(docling_docs):\n",
    "    print(\n",
    "        f\"[bold {BLUE}]> DOC N°:[/] [bold {WHITE}]{index}[/]\\n\",\n",
    "        f\"[bold {EMERALD}]> FILENAME:[/] [bold {WHITE}]{doc.metadata[\"filename\"]}[/]\\n\\n\",\n",
    "        f\"[bold {YELLOW}]> CONTENT:[/]\\n[{WHITE}]{doc.page_content}[/]\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyMuPDFLoader + Groq (Multimodal Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-groq pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.document_loaders.parsers import LLMImageBlobParser\n",
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "from pydantic import SecretStr\n",
    "\n",
    "GROQ_API_KEY = SecretStr(getpass(\"GROQ_API_KEY =\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL: ChatGroq = ChatGroq(\n",
    "    api_key=GROQ_API_KEY, model=\"llama-3.2-11b-vision-preview\", max_tokens=8192\n",
    ")\n",
    "\n",
    "PROMPT: str = (\n",
    "    \"You are an assistant tasked with extracting text from pdf files for retrieval.\"\n",
    "    + \" Extract only all the text from the pdf file.\"\n",
    "    + \" Do not exclude any text, except for the barcodes found in each page.\"\n",
    "    + \"\\nAnswer only with the text from the pdf file.\"\n",
    "    # + \"\\nFormat answer in markdown without explanatory text and without markdown delimiter ``` at the beginning. \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFLoader(\n",
    "    PDF_FILE_1,\n",
    "    mode=\"page\",\n",
    "    images_inner_format=\"text\",\n",
    "    images_parser=LLMImageBlobParser(\n",
    "        model=MODEL,\n",
    "        prompt=PROMPT,\n",
    "    ),\n",
    ")\n",
    "mmm_docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, doc in enumerate(mmm_docs):\n",
    "    for page in doc:\n",
    "        print(\n",
    "            f\"[bold {BLUE}]> DOC N°:[/] [bold {WHITE}]{index}[/]\\n\",\n",
    "            f\"[bold {EMERALD}]> FILENAME:[/] [bold {WHITE}]{page.metadata[\"title\"]}[/]\\n\\n\",\n",
    "            f\"[bold {YELLOW}]> CONTENT:[/]\\n[{WHITE}]{page.page_content}[/]\",\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
